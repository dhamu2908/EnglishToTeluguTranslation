{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4cja49MuCmupVtZTuep4M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhamu2908/EnglishToTeluguTranslation/blob/main/English_Telugu_Using_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CRbxogM2aDzz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "from collections import Counter, defaultdict\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simple RNN Cell**"
      ],
      "metadata": {
        "id": "PbremOEcaYBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN:\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    #input size : How many features each word has (embedding dimension)\n",
        "    #hidden size: how much memory RNN has\n",
        "\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    #weight matrix for input --> hidden(Wxh)\n",
        "\n",
        "    self.Wxh = np.random.randn(input_size, hidden_size) * 0.1\n",
        "\n",
        "    #weight matrix for hidden-->hidden (Whh)\n",
        "    self.Whh = np.random.randn(hidden_size, hidden_size) * 0.1\n",
        "\n",
        "    #Bias term\n",
        "    self.bh = np.zeros((1, hidden_size))\n",
        "\n",
        "  #Forward\n",
        "\n",
        "  def forward(self, x, h_prev):\n",
        "    #Process the current input\n",
        "    input_contributed = np.dot(x, self.Wxh)\n",
        "\n",
        "    memory_contribution = np.dot(h_prev, self.Whh)\n",
        "\n",
        "    combined = input_contributed + memory_contribution + self.bh\n",
        "\n",
        "    h_next = np.tanh(combined)\n",
        "\n",
        "    return h_next\n",
        "\n"
      ],
      "metadata": {
        "id": "jL3C81WvaQPQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Embedding**"
      ],
      "metadata": {
        "id": "HixpSBL9djFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Word2Vec:\n",
        "  def __init__(self):\n",
        "    self.model = None\n",
        "    self.vocab = {}\n",
        "    self.embeddings = None\n",
        "\n",
        "  def create_vocab(self, sentences):\n",
        "    self.vocab = {\"<PAD>\" : 0, \"<UNK>\" : 1}\n",
        "\n",
        "    #Adding all unique words\n",
        "    for sentence in sentences:\n",
        "      words = sentence.lower().split()\n",
        "      for word in words:\n",
        "        if word not in self.vocab:\n",
        "          self.vocab[word] = len(self.vocab)\n",
        "\n",
        "    print(f\"Vocab size : {len(self.vocab)}\")\n",
        "    return self.vocab\n",
        "\n",
        "  def train_word2vec(self, sentences, embedding_dim = 50):\n",
        "    print(\"Training Word2Vec ....\")\n",
        "\n",
        "    #Preparing sentences for word2vec\n",
        "\n",
        "    word_lists = []\n",
        "    for sentence in sentences:\n",
        "      words = sentence.lower().split()\n",
        "      word_lists.appened(words)\n",
        "\n",
        "    #Train word2vec\n",
        "    self.model = Word2Vec(sentences = word_lists, vector_size = embedding_dim,\n",
        "                          window = 3, min_count = 1, workers = 1)\n",
        "\n",
        "    print(\"Word2Vec trained with {embedding_dim} dimensions\")\n",
        "\n",
        "    return self.model\n",
        "\n",
        "  def create_embedding_matrix(self, vocab, embedding_dim):\n",
        "    print(\"Creating embedding matrix ....\")\n",
        "\n",
        "    vocab_size = len(vocab)\n",
        "\n",
        "    embeddings = np.random.randn(vocab_size, embedding_dim) * 0.1\n",
        "\n",
        "    found = 0\n",
        "\n",
        "    for word, index in vocab.items():\n",
        "      if word in self.model.wv:\n",
        "        embeddings[index] = self.model.wv[word]\n",
        "        found += 1\n",
        "\n",
        "    print(f\"{found} words found in embedding\")\n",
        "\n",
        "    self.embeddings = embeddings\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hPw6Q03qaQnn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kC-zE-fkaQqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LXyUlgTnaQsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QgxJ-toWaQvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bNp6qUOBaQxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EZO_IRZ9aQ0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NHhHGY6caQ2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M88c1Z8gaQ6E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}